#file: noinspection SpringBootApplicationYaml

spring:
  datasource:
    driver-class-name: org.apache.shardingsphere.driver.ShardingSphereDriver
    url: jdbc:shardingsphere:classpath:application-dev-shardingsphere-jdbc.yml
  hikari:
    minimum-idle: 10  # 确保连接池中始终保留至少 10 个空闲连接，供应用程序随时使用
    maximum-pool-size: 16  # 限制连接池中同时存在的最大连接数，避免数据库过载
    idle-timeout: 30000  # 空闲连接的超时时间
    max-lifetime: 1800000  # 连接的最大生命周期
    connection-timeout: 30000  # 获取连接的最大等待时间
  jpa:
    open-in-view: false  # 避免内存泄漏
    hibernate:
      ddl-auto: validate
      show-sql: true  # 在控制台显示sql语句
      properties:
        hibernate:
          format_sql: true  # 格式化sql语句
      naming:
        physical-strategy: org.hibernate.boot.model.naming.PhysicalNamingStrategyStandardImpl
  kafka:
    bootstrap-servers: localhost:9092  # kafka的地址
    producer: # 生产者配置
      acks: 1  # 只有在主副本确认时，生产者才认为消息已成功发送
      retries: 1   # 发送消息失败时，重试的次数
      batch-size: 16384   # 生产者在发送批次之前可以积累的最大字节数
      key-serializer: org.springframework.kafka.support.serializer.JsonSerializer  # 消息键的序列化器
      value-serializer: org.springframework.kafka.support.serializer.JsonSerializer  # 消息值的序列化器
      properties:
        linger.ms: 0  # 生产者在发送批次之前等待更多消息的时间
        buffer-memory: 33554432  # 生产者可以使用的缓冲区内存大小
        spring:
          json:
            trusted:
              packages: "*"  # 序列化时，信任的包
    consumer: # 消费者配置
      group.id: consumer_group_1   # 消费组的id
      # 偏移量
      enable-auto-commit: true    # 自动提交偏移量
      auto.commit.interval.ms: 1000  # 自动提交偏移量的时间间隔
      auto-offset-reset: earliest  # 当没有初始偏移量时，消费者从最早的消息开始消费
      # 心跳机制
      heartbeat.interval.ms: 3000  # 消费者发送心跳的时间间隔
      session.timeout.ms: 120000  # 消费者会话的超时时间
      request.timeout.ms: 180000  # 消费者请求的超时时间
      # poll
      max-poll-records: 50   # 单次poll返回的最大消息数
      max-poll-interval-ms: 5000   # 消费者在两次连续的poll之间可以等待的最大时间，消费者处理数据超过这个时间，会被认定为死亡
      # 反序列化
      key-deserializer: org.springframework.kafka.support.serializer.JsonDeserializer  # 消息键的反序列化器
      value-deserializer: org.springframework.kafka.support.serializer.JsonDeserializer  # 消息值的反序列化器
      properties:
        spring:
          json:
            trusted:
              packages: "*"  # 反序列化时，信任的包
      #    listener:  # 监听器配置
      # record：当每一条记录被消费者监听器（ListenerConsumer）处理之后提交
      # batch：当每一批poll()的数据被ListenerConsumer处理之后提交
      # time：当每一批poll()的数据被ListenerConsumer处理之后，距离上次提交时间大于TIME时提交
      # count：当每一批poll()的数据被ListenerConsumer处理之后，被处理record数量大于等于COUNT时提交
      # count_time：TIME或COUNT中有一个条件满足时提交
      # manual：当每一批poll()的数据被ListenerConsumer处理之后, 手动调用Acknowledgment.acknowledge()后提交
      # manual_immediate：手动调用Acknowledgment.acknowledge()后立即提交，一般推荐使用这种
      # ack-mode: manual_immediate

redis:
  address: redis://localhost:6379
  sdk:
    config:
      host: localhost
      port: 6379
      pool-size: 10
      min-idle-size: 5
      idle-timeout: 30000
      connect-timeout: 5000
      retry-attempts: 3
      retry-interval: 1000
      ping-interval: 60000
      keep-alive: true